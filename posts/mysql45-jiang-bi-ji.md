---
title: 'MySQL45 讲笔记'
date: 2024-12-08 08:56:12
tags: [mysql,geektime,note]
published: true
hideInList: false
feature: /post-images/mysql45-jiang-bi-ji.png
isTop: false
---
## 基础架构
![MySQL 基础架构](https://xuhang.github.io/post-images/1733619417022.png)

### 连接器

连接器负责跟客户端建立连接、获取权限、维持和管理连接。
- 如果用户名或密码不对，你就会收到一个"Access denied for user"的错误，然后客户端程序结束执行。
-   如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。

<!-- more -->

客户端如果太长时间没动静（show processlist结果的Command列显示为sleep），连接器就会自动将它断开。这个时间是由参数wait_timeout控制的，默认值是8小时。
MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，导致MySQL异常重启。
解决办法：
1.  定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
2.  如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

### 查询缓存
执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。

查询缓存的失效非常频繁，**只要有对一个表的更新，这个表上所有的查询缓存都会被清空**。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。

参数query_cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用SQL_CACHE显式指定，像下面这个语句一样：

```sql
mysql> select SQL_CACHE * from T where ID=10；
```

> MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。

### 分析器

分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。

做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。

### 优化器

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。

### 执行器

开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误。

如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。


## 日志系统

### 日志模块：redo log

如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。MySQL使用WAL技术来提升效率，WAL的全称是Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为**crash-safe**。

### 日志模块：binlog

上面聊到的redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）。

因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。

两种日志有以下三点不同。

1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
2. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。
3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

```sql
mysql> update T set c=c+1 where ID=2;
```

执行上面这条update语句时执行器和InnoDB引擎内部的流程：

1. 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

2. 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。

4. 执行器生成这个操作的binlog，并把binlog写入磁盘。

5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。

![执行器和InnoDB引擎内部的流程](https://xuhang.github.io/post-images/1733619501073.png)

innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。

> - binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：
>   - STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；
>   - ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；
>   - MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；
> - redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；

## 事务隔离

### 隔离性与隔离级别

事务拥有四个重要的特性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）

- **原子性** （Atomicity）

事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。

- **一致性** （Consistency）

指事务将数据库从一种状态转变为另一种一致的的状态。事务开始前和结束后，数据库的完整性约束没有被破坏。

- **隔离性** （Isolation）

要求每个读写事务的对象对其他事务的操作对象能互相分离，即该事务提交前对其他事务不可见。 也可以理解为多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。这指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。

> MySQL 通过锁机制来保证事务的隔离性。

- **持久性** （Durability）

事务一旦提交，则其结果就是永久性的。即使发生宕机的故障，数据库也能将数据恢复，也就是说事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。

| **隔离级别**     | 脏读 | **不可重复读** | **幻读** |
| ---------------- | ---- | -------------- | -------- |
| SERIALIZABLE     | 避免 | 避免           | 避免     |
| REPEATABLE READ  | 避免 | 避免           | 允许     |
| READ COMMITTED   | 避免 | 允许           | 允许     |
| READ UNCOMMITTED | 允许 | 允许           | 允许     |

>### 幻读和不可重复读的区别
>
>- 不可重复读的重点是修改：在同一事务中，相同的条件，第一次和第二次读到的数据不一致（中间有其它事务提交了修改）。
>- 幻读的重点是新增或者删除：在同一事务中，相同的条件，第一次和第二次读到的记录数不一样（中间有其它事务提交了新增或者删除）。

![隔离级别](https://xuhang.github.io/post-images/1733619524395.png)

在不同的隔离级别下，事务A的返回结果：

- 若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。
- 若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。
- 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。
- 若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。

在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“**可重复读**”隔离级别下，这个视图是在**事务启动时**创建的，整个事务存在期间都用这个视图。在“**读提交**”隔离级别下，这个视图是在每个**SQL语句开始执行**的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

### 事务隔离的实现

在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

>为什么尽量不要使用长事务？
>
>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。



*多版本并发控制*（Multiversion Concurrency Control），每一个写操作都会创建一个新版本的数据，读操作会从有限多个版本的数据中挑选一个最合适的结果直接返回；在这时，读写操作之间的冲突就不再需要被关注，而管理和快速挑选数据的版本就成了 MVCC 需要解决的主要问题。

#### MySQL与MVCC

MySQL 中实现的多版本两阶段锁协议（Multiversion 2PL）将 MVCC 和 2PL 的优点结合了起来，每一个版本的数据行都具有一个唯一的时间戳，当有读事务请求时，数据库程序会直接从多个版本的数据项中具有最大时间戳的返回。

更新操作就稍微有些复杂了，事务会先读取最新版本的数据计算出数据更新后的结果，然后创建一个新版本的数据，新数据的时间戳是目前数据行的最大版本 `＋1`：

数据版本的删除也是根据时间戳来选择的，MySQL 会将版本最低的数据定时从数据库中清除以保证不会出现大量的遗留内容。

#### 事务的起点

`begin`/`start transaction` 命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用`start transaction with consistent snapshot `这个命令。

在MySQL里，有两个“视图”的概念：

- 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view … ，而它的查询方法与表一样。
- 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。

### 事务的启动方式

MySQL的事务启动方式有以下几种：

1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。

## 索引

### InnoDB 的索引模型

在InnoDB中，表都是根据**主键顺序**以索引的形式存放的，这种存储方式的表称为索引组织表。

每一个索引在InnoDB里面对应一棵B+树。

根据叶子节点的内容，索引类型分为主键索引和非主键索引。

- 主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。
- 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。


> **基于主键索引和普通索引查询的区别**
>
> - 如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；
> - 如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为**回表**。
>
> *基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。*

### 覆盖索引

如果一个索引包含所有需要查询的字段的值，称为**覆盖索引**，即只需扫描索引而无须回表。由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。

### 最左前缀原则

对于联合索引的索引项是按照索引定义里面出现的字段顺序排序的，比如对列A，B，C建立联合索引，实际上是建立了(A)，(A, B)，(A, B, C)三个索引。

1. MySQL会一直向右匹配直到遇到范围查询(`>`、`<`、`between`、`like`)就停止匹配，比如A = 1 and B = 2 and C > 3 and D = 4 如果建立(A，B，C，D)顺序的索引，d是用不到索引的，如果建立(A，B，D，C)的索引则都可以用到，A，B，D的顺序可以任意调整。

2. `=`和`in`可以乱序，比如A = 1 and B = 2 and C = 3 建立(A，B，C)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。

**为什么要用联合索引**

- 减少开销。建一个（A，B，C）的联合索引，实际上是建立了(A)，(A, B)，(A, B, C)三个索引。
- 覆盖索引。联合索引（A，B，C）的叶节点包含ABC三列的数据，如果查询的列在（A，B，C）之中可以直接通过索引获取到数据，无需回表，减少树的随机IO。
- 效率高。通过联合索引筛选出的数据少，列越多数据越少

### 索引下推

对于**联合索引**中不符合最左前缀的部分，MySQL的处理方式：

- 在MySQL 5.6之前，只能从第一个满足最左前缀索引的数据开始一个个回表。到主键索引上找出数据行，再对比字段值。
- 而MySQL 5.6 引入的**索引下推优化**（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

也就是说在5.6之前的版本，不符合最左前缀的部分对InnoDB引擎是没用的，5.6及以后的版本进行了优化，直接在索引上进行筛选，减少回表次数。

### 普通索引

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

> 唯一索引的更新就不能使用change buffer

对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

## 锁

### 全局锁

全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都select出来存成文本。

对于支持事务的引擎，比如InnoDB，可以通过启动一个事务，确保拿到一致性视图，而且由于MVCC的支持，这个过程不需要锁库。对于不支持事务的引擎，比如MyISAM，就需要全局锁FTWRL来避免数据的更新。

> **set global readonly=true**的方式也能使整个库只读，但是这种方式有两个弊端：
>
> 1. 在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。
> 2. 在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时
> 3. 间处于不可写状态，风险较高。

### 表级锁

MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。

**表锁的语法是 lock tables … read/write。**与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

**另一类表级的锁是MDL（metadata lock)。**MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。

MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

- 读锁之间不互斥，因此你可以有多个线程同时对一张表**增删改查**。
- **读写锁**之间、**写锁**之间是互斥的，用来保证变更表结构操作的安全性。

| 时间线 | session A       | session B       | session C                        | session D               |
| ------ | --------------- | --------------- | -------------------------------- | ----------------------- |
| t1     | begin -> select |                 |                                  |                         |
| t2     |                 | begin -> select |                                  |                         |
| t3     |                 |                 | begin -> **alter table**【阻塞】 |                         |
| t4     |                 |                 |                                  | begin -> select【阻塞】 |

> **如何安全地给小表加字段？**
>
> 比较理想的机制是，在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。

```sql
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ... 
```

### 行锁

MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。

#### 两阶段锁

**在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**

> 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。这样事务之间锁等待的时间最少，提高并发度。

### 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

解决死锁的两种策略：

1. 直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置，但是会误伤等待非死锁的查询。
2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。但是死锁检测在并发情况下会消耗大量CPU资源。

结合实际情况中的场景，一般是启用死锁检测，控制客户端的并发数，这样死锁检测不至于太占用CPU资源。

## 如何保证数据不丢失

### binlog写入机制

事务执行过程中将日志写到 binlog cache，事务提交的时候，将 binlog cache 写入 binlog 文件中。一个事务的 binlog 是不能被拆分的，如果这个事务多的，都要确保一次性写入。系统给每个线程分配一个 binlog cache 内存区域（但是 binlog 文件只有一份），参数`binlog_cache_size`用于控制单个线程内 binlog cache 所占内存大小，如果超过这个大小，就要暂存到磁盘上。事务提交的时候，把 binlog cache 中的完整事务写入 binlog 中，并清空 binlog cache。

参数`sync_binlog`的含义：

+ `0` ：每次事务提交只 write（将 binlog cache 中内容写入文件系统的 page cache），不 fsync（将 page cache 中数据持久化到硬盘）
+ `1`：每次事务提交都会执行 fsync
+ `N`：每次提交都 write，但是累积 N 个事务后才 fsync

### redo log 写入机制

事务执行过程中将日志写到 redo log buffer，然后由`innodb_flush_log_at_trx_commit`参数控制 redo log 持久化的逻辑。

参数`innodb_flush_log_at_trx_commit`的含义：

+ `0`：每次事务提交只是把 redo log 留在 redo log buffer 中；
+ `1`：每次事务提交都将 redo log 持久化到硬盘；
+ `2`：每次事务提交只是把 redo log 写到 page cache。

同时，InnoDB 后台有个线程，每隔 1s，将 redo log buffer 中的日志调用 write 写到文件系统的 page cache 中，然后调用 fsync 持久化到硬盘。所以事务未提交时，redo log buffer 中的内容也有可能被持久化到硬盘上。

此外，还有 2 种情况会让没有提交的事务的 redo log 写入磁盘：

1. redo log buffer 占用空间即将达到`innodb_log_buffer_size`的一半时，后台线程会主动写盘(write，没有 fsync)。
2. 并行事务提交时，顺带将这个事务的 redo log buffer 持久化到磁盘。

### 组提交（Group commit）机制

日志逻辑序列号（log sequence number, LSN）:单调递增，对应 redo log 上的一个个写入点，每次写入长度为 length 的 redo log，LSN 的值就会加上 length。

LSN 也会写到 InnoDB 的数据页中，用来确保数据页不会被多次执行重复的 redo log。

多个事务同时执行，最先到达的会被选为这组的 leader；leader 写盘的时候会将整组的 redo log 一起持久化，组员越多，节约 IOPS 的效果越好。

`binlog_group_commit_sync_delay`：binlog 调用 write 多少微妙后才调用 fsync

`binlog_group_commit_sync_no_delay_count`：累积多少次后调用 fsync

## 如何保证主备一致

通常将备库设置成只读(readonly)，可以方便地判断节点状态，但是 readonly 并不影响备库和主库保持同步。同步更新的线程，拥有超级权限，而 readonly 对超级权限用户是无效的。

事务日志同步的完整过程：

1. 备库上通过`change master`命令设置主库 IP、端口、用户名、密码以及 binlog 文件名和日志偏移量（从哪个位置开始请求 binlog）
2. 在备库上执行`start slave`命令，启动`io_thread`和`sql_thread`两个线程，分别用于负责与主库建立连接和解析日志执行
3. 主库校验完用户名密码后，按照备库制定的文件和位置，读取 binlog 发送给备库
4. 备库拿到 binlog 后写入本地文件（中转日志 relay log）
5. sql_thread 从中转日志读取并解析，然后执行

### binlog 的三种格式

+ `STATEMENT`：binlog 记录的时原始 SQL 语句（可能导致主备不一致）
+ `ROW`：记录的是受影响的记录（占用空间），但是方便恢复数据
+ `MIXED`：由 MySQL 判断是否会影响主备不一致选择 ROW 或 STATEMENT

>通过 SQL查看 binlog 中的内容：
>
>```show binlog events in 'xxxx.0000001';```
>
>借助 mysqlbinlog 工具查看 binlog 详细信息：
>
>```mysqlbinlog -vv data/master.000001[binlog 文件] --start-position=9xxx[从指定行开始解析] --stop-position=9xxx[解析截止到制定行]```

